<section>
  <title>Inverse Matrices</title>
  <p>
    The identity property:
    <m>AI_l = I_k A = A</m> reminds us of multiplication by one in <m>\RR</m>.
    This is the multiplication that doesn't accomplish anything.
    In number systems, when we have an identity,
    we usually have a way of getting back to that identity.
    Zero is the identity in addition.
    For any number <m>a</m>,
    we have <m>(-a)</m> so that
    <m>a + (-a) = 0</m> gets us back to the identity.
    One is the identity in multiplication.
    For any <em>non-zero</em> number <m>a</m>,
    we have <m>\frac{1}{a}</m> so that
    <m>a \frac{1}{a} = 1</m> gets us back to the identity.
  </p>
  <p>
    For matrices, we have the same question.
    For any matrix <m>M</m>,
    is there another matrix <m>N</m> such that <m>MN = I</m>?
    Multiplication of numbers alreay shows us that we need to take care:
    for the number zero, there is no such number.
    For matrices, we have to be even more cautious.
  </p>
  <definition>
    <statement>
      <p>
        Let <m>M</m> be a <m>n \times n</m> (square) matrix.
        The the <term>inverse</term> of <m>M</m> is the
        <term>unique</term> matrix <m>M^{-1}</m>
        (if it exists)
        such that <m>MM^{-1} = M^{-1}M = I_n</m>.
      </p>
    </statement>
  </definition>
  <p>
    We should note a couple of thing about this definition.
    First, it only applies to square matrices.
    We don't even try to invert non-square matrices.
    Second, we need to have both orders of multiplication <m>MM^{-1}</m> and <m>M^{-1}M</m>.
    This is due to the previous observation that matrix multiplication is non-commutative.
    In general, these two orders could result in different products.
    In this case,
    we insist that both orders get us back to the identity.
  </p>
</section>