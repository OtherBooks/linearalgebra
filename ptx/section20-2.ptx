<section>
  <title>Calculation of Eigenvalue and Eigenvectors</title>
  <p>
    We would like to have an algorithm for finding eigenvectors and eigenvalues.
    Remember the definition:
    <m>v</m> is an eigenvector of <m>A</m> if
    <m>Av = \lambda v</m> for some real number <m>\lambda</m>.
    We can write the scalar multiplication
    <m>\lambda v</m> as <m>\lambda \Id v</m>,
    since the matrix <m>\lambda \Id</m> multiplies each entry by <m>\lambda</m>.
    Therefore, the equation becomes
    <m>Av = \lambda \Id v</m> or <m>Av - \lambda \Id v = 0</m>,
    where the right hand side is the zero vector.
    Since matrix action is linear,
    this is the same as <m>(A - \lambda \Id) v = 0</m>.
  </p>
  <p>
    We assumed that <m>v</m> was non-zero in the definition of eigenvectors.
    Therefore, the matrix <m>(A - \lambda \Id)</m> sends a non-zero vector <m>v</m> to the zero vector.
    This implies <m>(A - \lambda \Id)</m> has a non-trivial kernel,
    hence must have zero determinant.
    Thererfore, a necessary condition for the existence of a eigenvector with eigenvalue <m>\lambda</m> is that <m>\det (A - \lambda \Id) = 0</m>.
    We start our algorithm by computing this determinant.
  </p>
  <p>
    This determinant has terms which involve the entries of <m>A</m> and <m>\lambda</m>.
    Since <m>A</m> is an <m>n \times n</m> matrix,
    each term can be the product of <m>n</m> entries.
    That means that the determinant will be a degree <m>n</m> polynomial in the variable <m>\lambda</m>.
  </p>
  <definition>
    <statement>
      <p>
        Let <m>A</m> be an <m>n \times n</m> matrix The polynomial
        <m>\det (A - \lambda \Id)</m> in the variable <m>\lambda</m> is called the
        <term>characteristic polynomial</term> of the matrix.
      </p>
    </statement>
  </definition>
  <p>
    We need an important definition about the roots of polynomials.
    Recall that <m>\alpha</m> is a root of a polynomial <m>p(\lambda)</m> if and only if
    <m>(\lambda - \alpha)</m> is a factor of the polynomial.
    However, it may be true that
    <m>(\lambda - \alpha)^m</m> is a factor for some integer <m>m>1</m>.
  </p>
  <definition>
    <statement>
      <p>
        Let <m>p(\lambda)</m> be a polynomial in the variable <m>\lambda</m> and <m>\alpha</m> a root.
        Let <m>m</m> be the largest positive integer such that
        <m>(\lambda - \alpha)^m</m> is a factor of <m>p(\lambda)</m>.
        Then <m>m</m> is called the <term>multiplicity</term>
        of the root <m>\alpha</m>.
      </p>
    </statement>
  </definition>
  <p>
    A degree <m>n</m> polynomial has at most <m>n</m> real roots,
    so we can find at most <m>n</m> values for <m>\lambda</m> where the determinant vanishes.
    These will be the possible eigenvalues.
    However, the polynomial also have at most <m>n</m> factors,
    so the sum of all the multiplicities of the roots is also at most <m>n</m>.
    That implies that if we have roots with higher multiplicities,
    we will certainly have fewer than <m>n</m> roots.
  </p>
  <p>
    Now we return to the eigenvalue/eigenvector algorithm.
    When we have an eigenvalue <m>\lambda</m>,
    we then want to find the matching eigenvectors.
    These vectors will be in the kernel of <m>(A - \lambda \Id)</m>,
    so we just have to calcluate this kernel.
  </p>
  <p>
    The second step will always find eigenvectors:
    the determinant of the matrix is zero,
    so it must have a non-trivial kernel.
    However, we don't know now many we will find
    (we don't know the dimension of the kernel).
    In the first step,
    we are looking for roots of a polynomials of degree <m>n</m>.
    It may have as many as <m>n</m> distinct real roots,
    but it may have far fewer or even none.
    Recall the identity and the zero matrix,
    where all vectors in <m>\RR^n</m> are eigenvectors for the appropriate eigenvalues,
    and also the rotations in <m>\RR^2</m> where there were no eigenvectors for any eigenvalue.
    Also note that solving for roots of polynomials,
    particular in high degrees, is a very hard problem.
  </p>
  <p>
    We have a definition that helps us keep track of this information.
  </p>
  <definition>
    <statement>
      <p>
        Let <m>A</m> be a <m>n \times n</m> matrix and let <m>\lambda</m> be an eigenvalue of <m>A</m>.
        Then the <term>eigenspace</term> of <m>\lambda</m>,
        written <m>E(\lambda)</m>,
        is the set of all eigenvectors for the eigenvalue <m>\lambda</m>.
        Equivalently,
        it is the kernel of the matrix <m>A - \lambda \Id</m>.
        The dimension of the eigenspace associated to <m>\lambda</m> is bounded by the multiplicity of <m>\lambda</m> as a root of the characteristic polynomial.
      </p>
    </statement>
  </definition>
  <example>
    <statement>
      <me>
        A = \left( \begin{matrix}
        3 \amp  1 \\ 1 \amp  3
        \end{matrix} \right)
        \implies A - \lambda \Id =
        \left( \begin{matrix}
        3-\lambda \amp  1 \\ 1 \amp  3 - \lambda
        \end{matrix} \right)
      </me>
      <p>
        The determinant of this is <m>9 - 6\lambda + \lambda^2 - 1 = 8-6\lambda + \lambda^2 = (\lambda-4)(\lambda-2)</m>.
        So the eigenvalues are <m>\lambda = 4</m> and <m>\lambda = 2</m>.
        We calculate the kernel of
        <m>A - \lambda \Id</m> first for <m>\lambda = 2</m>.
        <me>
          A - 2 \Id = \left( \begin{matrix} 1 \amp  1 \\ 1 \amp  1 \end{matrix} \right)
        </me>
      </p>
      <p>
        The kernel of this matrix is <m>\Span</m><img src="MISSINGFILE"  width="400" /> . All multiples of <img src="MISSINGFILE"  width="400" /> are eigenvectors for <m>\lambda = 2</m>.
        Next we move on to <m>\lambda = 4</m>.
        <me>
          A - 4 \Id = \left( \begin{matrix} -1 \amp  1 \\ 1 \amp  - 1 \end{matrix} \right)
        </me>
      </p>
      <p>
        The kernel of this matrix is <m>\Span</m><img src="MISSINGFILE" width="400" /> . All multiples of <img src="MISSINGFILE" width="400" /> are eigenvectors for <m>\lambda = 4</m>.
      </p>
    </statement>
  </example>
  <example>
    <statement>
      <me>
        A = \left( \begin{matrix}
        0 \amp  -2 \\ 2 \amp  0
        \end{matrix} \right)
        \implies A - \lambda \Id =
        \left( \begin{matrix}
        -\lambda \amp  -2 \\ 2 \amp  -\lambda
        \end{matrix} \right)
      </me>
      <p>
        The characteristic polynomial is <m>\lambda^2 + 4 = 0</m>,
        which has no roots.
        Therefore, there are no eigenvalues.
      </p>
    </statement>
  </example>
  <example>
    <statement>
      <p>
        Consider a diagonal matrix.
        <me>
          A = \left( \begin{matrix} 1 \amp  0 \amp  0 \amp  0 \\ 0 \amp  -3 \amp  0 \amp  0 \\ 0 \amp  0 \amp  4 \amp  0 \\ 0 \amp  0 \amp  0 \amp  0 \end{matrix} \right) \implies A - \lambda \Id = \left( \begin{matrix} 1 - \lambda \amp  0 \amp  0 \amp  \\ 0 \amp  -3 - \lambda \amp  0 \amp  0 \\ 0 \amp  0 \amp 4 - \lambda \amp  0 \\ 0 \amp  0 \amp  0 \amp  - \lambda \end{matrix} \right)
        </me>
      </p>
      <p>
        The characteristic polynomial is <m>(1-\lambda)(-3-\lambda)(4-\lambda)(-\lambda)</m>,
        which clearly has solutions <m>\lambda = 1</m>,
        <m>-3</m>, <m>4</m> and <m>0</m>.
        The eigenvectors are just the axis vectors <m>e_1</m>,
        <m>e_2</m>, <m>e_3</m> and <m>e_4</m>, respectively.
        As we said before,
        diagonal matrices have axis vectors as eigenvectors and diagonal entries as eigenvalues.
      </p>
    </statement>
  </example>
</section>